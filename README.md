# newsclassification  第十届“中国软件杯”大学生软件设计大赛新闻文本分类算法
1数据集的收集以及预处理
1.1收集新闻数据
1）软件杯比赛官方提供的xlsx表格数据：比赛官方的数据集提供了财经、房产、教育、科技、军事、汽车、体育、游戏、娱乐、其他，十个分类一共14000余条新闻数据，新闻总数较少，并且十类新闻的数量分布不均匀，财经类最多，有8000余条新闻，房产类只有200条新闻，而其他类一栏为空白没有提供数据。为了弥补官方数据集的不足，我们需要更多的途径来获取数据。
2）现成的新闻文本分类数据集（THUCNews) ：THUCNews是由清华大学制作的开源新闻文本分类数据集，包含了14个类别大约74万条中文新闻。该数据集的优点是新闻数量多，缺点是年代较为久远（大约十年前），在新闻时效性上有所欠缺并且分类没有包含比赛要求的全部分类（没有汽车以及军事新闻）。本项目选取了该数据集中的财经、房产、教育、科技、体育、游戏、娱乐七个类别一共约6万条新闻归入比赛要求的相应类别。选取该数据集中的社会、时尚、时政、星座四个类别一共约7000条新闻归入其他类。弃用分类较为模糊的股票、彩票、家居类。
3）使用爬虫技术从新闻网站爬取新闻：我们使用基于Python的网络爬虫库Beautifulsoup，从新浪、网易、搜狐、腾讯等新闻网站爬取新闻。针对THUCNews中没有的类别（汽车类和军事类），我们分别各爬取了大约1万条军事、汽车新闻。对于时效性较为敏感的游戏类和娱乐类新闻，我们也分别各爬取了约7000条作为更新。我们另外爬取了农业、艺术、政务、法律等类别一共3000余条新闻归入其他类别。
从以上三种途径，我们一共获取了大约10万条新闻数据，每个类别新闻数量都大约为1万条。
1.2数据清洗
文本分类模型对于文本输入的长度有限制，数据清洗可以减少无用信息的输入，减少计算资源的消耗，并且使得文本的主题更容易显现，从而提高分类模型的性能，提高预测的准确度及F1值。
我们首先通过手动的方式，将数据集中分类明显错误的新闻调整到正确的分类。以官方数据集为例，我们将娱乐类中频道名为“体育焦点”的400余条新闻调整到体育类中并删除那些内容或者标题为空白的新闻。
然后，我们编写Python脚本，通过正则表达式的方式来对新闻的文本内容进行过滤清洗。包括去除特殊符号、去除日期、去除网址以及去除停用词等一系列操作。并且，我们针对新闻文本的特点，制定了一个停用词列表。
数据清洗的具体实现详见代码clean.py。

2 核心算法
2.1 语言表征模型ALBERT
本项目使用的语言表征模型为ALBERT（A Lite BERT)模型 ，是BERT模型的一种改进版本，相比于目前普遍使用的BERT模型作了如下改进：
①　通过嵌入层因式分解缩减了嵌入层参数；
②　通过跨层参数共享机制使得多层参数量缩减为一层；
③　改进了语言模型训练策略，由NSP（下一句预测）改为SOP（句子顺序预测）；
相比于BERT模型，ABERT模型具有在保证了预测精度的同时，模型训练速度快，需要的计算资源少，以及对硬件的配置要求相对较低的优点。
2.2 参数设置
（1）模型固有参数
本项目使用的模型为ALBERT_BASE 中文预训练模型 12-layer, 768-hidden, 12M parameters（12层隐藏层，768个隐藏单元，12M参数量）相比BERT_BASE模型，参数量由110M缩减至12M，缩减了九倍。
（2）模型超参数设置
学习率设为1e-5；Dropout（丢弃率）设为0.1（为防止过拟合，模型在训练过程中的已学习参数会以一定比例随机丢弃）；文本长度限制：设为254，具体到新闻文本分类任务，我们限制新闻内容加标题的长度不长于254个字符。如果新闻长度大于254，我们截取文本的前254个字符；Epoch（迭代次数）设为3；Bach_size（每批同时训练的样本数量）设为8。
（3）训练集以及测试集的划分
数据集中的所有数据以4比1的比例随机分配为训练集和验证集。本项目收集了一共约10万条新闻数据，其中8万条作为训练集，2万条作为测试集。


在我们自己准备的2万条测试集中得到的评估结果如下：
新闻类别	体育	教育	财经	房产	汽车	科技	军事	游戏	娱乐	其他	平均
精确率（Precision）	0.9858	0.9632	0.9640	0.9899	0.9726	0.9236	0.9978	0.9695	0.9480	0.9102	0.9624
召回率（Recall）	0.9872	0.9826	0.9209	0.9461	0.9769	0.9475	0.9625	0.9669	0.9792	0.9608	0.9631
F1值	0.9865	0.9728	0.9420	0.9675	0.9747	0.9354	0.9798	0.9682	0.9633	0.9348	0.9625
准确率（Accuracy）	0.9621
